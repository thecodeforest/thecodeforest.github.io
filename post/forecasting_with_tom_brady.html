<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.30.2" />
  <meta name="author" content="Mark LeBoeuf">
  <meta name="description" content="Data Scientist">

  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/monokai.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  


  

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-101855339-2', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="The Code Forest">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="The Code Forest">
  

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="/post/forecasting_with_tom_brady.html">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="The Code Forest">
  <meta property="og:url" content="/post/forecasting_with_tom_brady.html">
  <meta property="og:title" content="Forecasting with Tom Brady | The Code Forest">
  <meta property="og:description" content="">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-08-16T21:13:14-05:00">
  
  <meta property="article:modified_time" content="2017-08-16T21:13:14-05:00">
  

  

  <title>Forecasting with Tom Brady | The Code Forest</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">The Code Forest</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>About</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">Forecasting with Tom Brady</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-08-16 21:13:14 -0500 -0500" itemprop="datePublished">
      Aug 16, 2017
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    17 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/forecasting_with_tom_brady.html#disqus_thread"></a>
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/forecasting">Forecasting</a
    >, 
    
    <a href="/categories/r">R</a
    >, 
    
    <a href="/categories/python">Python</a
    >, 
    
    <a href="/categories/web-scraping">Web Scraping</a
    >, 
    
    <a href="/categories/arima">ARIMA</a
    >, 
    
    <a href="/categories/sports-betting">Sports Betting</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Forecasting%20with%20Tom%20Brady&amp;url=%2fpost%2fforecasting_with_tom_brady.html"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fforecasting_with_tom_brady.html"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fforecasting_with_tom_brady.html&amp;title=Forecasting%20with%20Tom%20Brady"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fforecasting_with_tom_brady.html&amp;title=Forecasting%20with%20Tom%20Brady"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Forecasting%20with%20Tom%20Brady&amp;body=%2fpost%2fforecasting_with_tom_brady.html">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        <p><img src="forecasting_with_tom_brady_images/hey_tom.jpg" width="800px" height="800px" /></p>
<p>Imagine it‚Äôs January 1st, 2015 and the New England Patriots made the playoffs yet again üò¢. You run a Tom Brady Super Fan website and want to ensure you have enough servers to accommodate traffic to your website during the playoffs. Historically, site traffic during January and February increases when the Patriots win playoff games, so you want a forecast for these months to determine how many people will visit your site.</p>
<p>You also want to quantify the effect of the number of playoff games won on monthly traffic. For example, what happens if the Patriots win two playoff games instead of one? Finally, you want an estimate of the probability of each of these scenarios unfolding‚Äìthat is, the chances the Patriot‚Äôs winning zero, one, two, or all three playoff games. To address each of these questions, you‚Äôll need the following sources of data:</p>
<ul>
<li><strong>Month level internet traffic</strong></li>
<li><strong>Historical game outcomes</strong></li>
<li><strong>Historical betting lines</strong></li>
</ul>
<p>I‚Äôll go through process of collecting each data source and then we‚Äôll generate some forecasts!</p>
<div id="collecting-month-level-traffic" class="section level3">
<h3>Collecting Month Level Traffic</h3>
<p>Let‚Äôs start by loading the required libraries and collecting historical page views. The page-view data comes from Wikipedia, which we assume emulates traffic volume to our website. We‚Äôll first pull the data into R via the <code>wp_trend</code> function, and then aggregate daily page views up to the monthly level.</p>
<pre class="r"><code>libs = c(&#39;wikipediatrend&#39;, &#39;dplyr&#39;, &#39;data.table&#39;, 
         &#39;rvest&#39;, &#39;forecast&#39;, &#39;lubridate&#39;,
         &#39;janitor&#39;,&#39;knitr&#39;, &#39;ggplot2&#39;, 
         &#39;forcats&#39;, &#39;lazyeval&#39;, &#39;readr&#39;,
         &#39;emo&#39;
         )
lapply(libs, require, character.only = TRUE)
wiki_query = &quot;Tom Brady&quot;
start_date = &quot;2006-09-01&quot;
end_date = &quot;2015-03-01&quot;
working_directory = &quot;your_working_directory&quot;
setwd(working_directory)
page_views = wp_trend(wiki_query, 
                      from = start_date,
                      to = end_date) %&gt;% 
             mutate(date = as.Date(date)) %&gt;% 
             mutate(year = year(date),
                    month = month(date)) %&gt;% 
             group_by(year, month) %&gt;% 
             mutate(max_month_date = max(date),
                    page_views = sum(page_views)) %&gt;%
             select(year, month, 
                    max_month_date, page_views) %&gt;% 
             distinct() %&gt;% 
             filter(year &gt; 2007 &amp; max_month_date &lt; as.Date(&quot;2015-03-01&quot;))</code></pre>
<p>Let‚Äôs have a look at the first few rows.</p>
<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:400px; overflow-x: scroll; width:720px; ">
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
year
</th>
<th style="text-align:center;">
month
</th>
<th style="text-align:center;">
max_month_date
</th>
<th style="text-align:center;">
page_views
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2008-01-30
</td>
<td style="text-align:center;">
452183
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
2008-02-29
</td>
<td style="text-align:center;">
414347
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
2008-03-31
</td>
<td style="text-align:center;">
74711
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
2008-04-30
</td>
<td style="text-align:center;">
83526
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2008-05-31
</td>
<td style="text-align:center;">
74857
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
2008-06-30
</td>
<td style="text-align:center;">
54377
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
2008-07-12
</td>
<td style="text-align:center;">
20042
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
2008-08-31
</td>
<td style="text-align:center;">
83623
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
2008-09-30
</td>
<td style="text-align:center;">
201761
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
2008-10-31
</td>
<td style="text-align:center;">
105190
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
2008-11-30
</td>
<td style="text-align:center;">
95206
</td>
</tr>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
2008-12-31
</td>
<td style="text-align:center;">
127058
</td>
</tr>
<tr>
<td style="text-align:center;">
2009
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2009-01-31
</td>
<td style="text-align:center;">
143411
</td>
</tr>
<tr>
<td style="text-align:center;">
2009
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
2009-02-28
</td>
<td style="text-align:center;">
116640
</td>
</tr>
<tr>
<td style="text-align:center;">
2009
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
2009-03-31
</td>
<td style="text-align:center;">
113011
</td>
</tr>
</tbody>
</table>
</div>
<p>Looks good! One thing to note is that the <code>max_month_date</code> field is simply the last day for that year-month combination. This field will be used for plotting. Next we‚Äôll pull down some actual game data.</p>
</div>
<div id="collecting-historical-game-data" class="section level3">
<h3>Collecting Historical Game Data</h3>
<p>We are interested in how the New England Patriots have historically performed during the playoffs. To obtain this information, we‚Äôll switch over to Python to scrape the outcomes (win or lose) of the Patriots vs.¬†each of the other 31 NFL teams. The <code>collect_game_data.py</code> is the script we‚Äôll execute. Feel free to configure the scripts and directories however you like, but I‚Äôve located everything - data and scripts - in the <code>working_directory</code>.</p>
<pre class="python"><code>from urllib import urlopen
import re
import pandas as pd
from bs4 import BeautifulSoup
import sys
import os.path
base_url = &#39;http://www.footballdb.com/teams/nfl/new-england-patriots/teamvsteam?opp=&#39;
game_data = []
n_teams = 32
output_location = os.path.join(sys.argv[1], sys.argv[2])
for team_number in range(1, n_teams + 1, 1):
    page  = str(BeautifulSoup(urlopen(base_url + str(team_number)), 
                              &#39;html.parser&#39;).findAll(&quot;table&quot;))
    for row in [x.split(&quot;&lt;td&gt;&quot;) for x in page.split(&quot;row&quot;)]:
        try:
            game_date, outcome = str(re.findall(&#39;gid=(.*)&#39;, row[4])).split(&quot;&gt;&quot;)[:2]
            game_data.append([game_date[2:10], outcome[0]])
        except:
            continue
game_data_df = pd.DataFrame(game_data)
game_data_df.columns = [&#39;date&#39;, &#39;outcome&#39;]
game_data_df.to_csv(output_location,  index = False)</code></pre>
<p>Below we‚Äôll call the <code>exe_py_script</code> function to collect the game data, and then write the result to a .csv file. Here is how we‚Äôll execute it from R.</p>
<pre class="r"><code>exe_py_script = function(py_bin_location, py_script_path, py_script_name, py_args){
  exe_command = paste(py_bin_location,
                      file.path(py_script_path, py_script_name),
                      paste(py_args, collapse = &quot; &quot;),
                      sep = &quot; &quot;)
  system(exe_command)
}

py_bin_location =  &quot;//anaconda/bin/python&quot;
py_script_path = working_directory
output_file_name = &quot;game_data.csv&quot;
py_script_name = &quot;collect_game_data.py&quot;
py_args = c(working_directory, output_file_name)
exe_py_script(py_bin_location, py_script_path, py_script_name, py_args)
game_data = read_csv(output_file_name)</code></pre>
<p>If you aren‚Äôt familiar with executing scripts in other languages from R (or the terminal), we can break this command down into further detail. There are four arguments passed to the function executing the python script:</p>
<ul>
<li><strong>py_bin_location: The location of the Python binaries on your machine ‚Äò//anaconda/bin/python‚Äô</strong></li>
<li><strong>py_script_path: The location of the Python script ‚Äòworking_directory‚Äô</strong></li>
<li><strong>py_script_name: The name of the Python script ‚Äòcollect_game_data.py‚Äô</strong></li>
<li><strong>py_args: Additional arguments passed into the Python script ‚Äòthe write-location of .csv‚Äô</strong></li>
</ul>
<p>Let‚Äôs do the scraping and see what we get back. Recall that we are executing all of the commands from within R.</p>
<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:400px; overflow-x: scroll; width:720px; ">
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
date
</th>
<th style="text-align:center;">
outcome
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
20160911
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
20120916
</td>
<td style="text-align:center;">
L
</td>
</tr>
<tr>
<td style="text-align:center;">
20081221
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
20040919
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
19991031
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
19960915
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
19931010
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
19910929
</td>
<td style="text-align:center;">
L
</td>
</tr>
<tr>
<td style="text-align:center;">
19901125
</td>
<td style="text-align:center;">
L
</td>
</tr>
<tr>
<td style="text-align:center;">
19841202
</td>
<td style="text-align:center;">
L
</td>
</tr>
<tr>
<td style="text-align:center;">
19811129
</td>
<td style="text-align:center;">
L
</td>
</tr>
<tr>
<td style="text-align:center;">
19780910
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
20171022
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
20170205
</td>
<td style="text-align:center;">
W
</td>
</tr>
<tr>
<td style="text-align:center;">
20130929
</td>
<td style="text-align:center;">
W
</td>
</tr>
</tbody>
</table>
</div>
<p>The data contains the date and outcome (Win or Lose) for every game the Patriots have played. We‚Äôll generate two features:</p>
<ul>
<li><strong>A sum of the playoff games played in Jan/Feb</strong></li>
<li><strong>A sum of the playoff games won in Jan/Feb</strong></li>
</ul>
<p>It‚Äôs not clear whether simply playing in a playoff game or winning a game drives traffic, so both features will be created. We‚Äôll then test to determine which corresponds more closely with web traffic.</p>
<pre class="r"><code>playoff_data = game_data %&gt;% 
               mutate(date = as.Date(as.character(date), format = &#39;%Y%m%d&#39;),
                      outcome = ifelse(outcome == &quot;W&quot;, 1, 0)) %&gt;% 
               mutate(year = year(date),
                      month = month(date, label = TRUE),
                      week = week(date)) %&gt;% 
               mutate(playoff_game = ifelse(month %in% c(&quot;Jan&quot;, &quot;Feb&quot;) &amp; week != 1, 
                               1, 
                               0)) %&gt;% 
               mutate(playoff_game_win = ifelse(outcome == 1 &amp; playoff_game == 1, 
                                   1, 
                                   0)) %&gt;% 
               group_by(year) %&gt;% 
               summarise(playoff_games_won = sum(playoff_game_win),
                         playoff_games_played = sum(playoff_game)) %&gt;% 
               filter(year &lt;= 2015 &amp; year &gt;= 2008)</code></pre>
<p>Again let‚Äôs see what the last few rows of the data look like:</p>
<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:300px; overflow-x: scroll; width:720px; ">
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
year
</th>
<th style="text-align:center;">
playoff_games_won
</th>
<th style="text-align:center;">
playoff_games_played
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
2008
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
2009
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
2010
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
2011
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
2012
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
2013
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
2014
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
2015
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
3
</td>
</tr>
</tbody>
</table>
</div>
<p>We have our playoff features built, and now it‚Äôs time to merge them with the monthly page views.</p>
<pre class="r"><code>page_views = inner_join(page_views, 
                        playoff_data
                        ) %&gt;% 
             mutate(part = ifelse(year == 2015, 
                                  &quot;test&quot;, 
                                  &quot;train&quot;),
                   playoff_games_won = ifelse(month %in% c(1, 2), 
                                              playoff_games_won, 
                                              0),
                   playoff_games_played = ifelse(month %in% c(1, 2), 
                                                 playoff_games_played, 
                                                 0))</code></pre>
<p>Our analytical dataset is ready for forecasting. We‚Äôll start, like most data-related activities, with a high-level visualization of the relationship between playoff wins and web traffic.</p>
</div>
<div id="visualizing-wins-vs.traffic" class="section level3">
<h3>Visualizing Wins vs.¬†Traffic</h3>
<pre class="r"><code>my_plot_theme = function(){
    font_family = &quot;Helvetica&quot;
    font_face = &quot;bold&quot;
    return(theme(
    axis.text.x = element_text(size = 18, face = font_face, family = font_family),
    axis.text.y = element_text(size = 18, face = font_face, family = font_family),
    axis.title.x = element_text(size = 20, face = font_face, family = font_family),
    axis.title.y = element_text(size = 20, face = font_face, family = font_family),
    strip.text.y = element_text(size = 18, face = font_face, family = font_family),
    plot.title = element_text(size = 18, face = font_face, family = font_family),
    legend.position = &quot;top&quot;,
    legend.title = element_text(size = 16,
    face = font_face,
    family = font_family),
    legend.text = element_text(size = 14,
    face = font_face,
    family = font_family)
))
}
color_values = c(&quot;#272822&quot;, &quot;#66D9EF&quot;,&quot;#F92672&quot;,&quot;#A6E22E&quot;, &quot;#A6E22E&quot;, &quot;#F92672&quot;)</code></pre>
<pre class="r"><code>page_views %&gt;% 
  filter(part == &#39;train&#39;) %&gt;% 
  mutate(playoff_games_won = as.factor(playoff_games_won)) %&gt;% 
  ggplot(aes(x  = max_month_date, y = page_views)) + 
  geom_point(aes(color = playoff_games_won), size = 4) + 
  geom_line() + 
  theme_bw() + 
  scale_color_manual(values = color_values[1:3],
                     guide = guide_legend(title = &quot;Playoff Games Won&quot;)) +
  my_plot_theme() + 
  xlab(&quot;Date&quot;) + 
  ylab(&quot;Page Views&quot;)</code></pre>
<p><img src="/post/forecasting_with_tom_brady_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
<p>The above plot suggests that playoff wins do relate to page views. Now we‚Äôll do some validation to see if including this information as an external regressor improves our forecasts.</p>
</div>
<div id="model-selection-and-validation" class="section level3">
<h3>Model Selection and Validation</h3>
<p>Since the forecasting period of interest is Jan/Feb 2015, we‚Äôll hold out two months of traffic volume from Jan/Feb 2014 as a way to identify which inputs will likely yield the most accurate forecasts. An ARIMA model with a single external regressor (games won or games played) will be used to generate the forecasts. The accuracy between the two models with external regressors (games played and games won) will be compared against a model that relies only on history (i.e., no external regressors).</p>
<pre class="r"><code>val_df = page_views %&gt;% 
  filter(part == &#39;train&#39;) %&gt;% 
  mutate(part = ifelse(year == 2014 &amp; month %in% c(1, 2),
                       &quot;validation&quot;, &quot;train&quot;
                       )) %&gt;% 
  filter(part == &#39;validation&#39;)
train_df = page_views %&gt;% 
           filter(max_month_date &lt; min(val_df$max_month_date))
# create our time-series object 
page_views_ts = ts(train_df$page_views,
                   frequency = 12,
                   start = c(head(train_df, 1)$year, 
                             head(train_df, 1)$month),
                   end = c(tail(train_df, 1)$year, 
                           tail(train_df, 1)$month)
                   )
# specify forecast horizon
horizon = 2
# arima model with no external regressors
f_no_xreg = forecast(auto.arima(page_views_ts), 
                     h = horizon)$mean
#  with playoff games played
f_playoff_played = forecast(auto.arima(page_views_ts,
                                       xreg = train_df$playoff_games_played),
                            h = horizon, xreg = val_df$playoff_games_played)$mean
#  with playoff games won                                
f_playoff_won = forecast(auto.arima(page_views_ts,
                                    xreg = train_df$playoff_games_won),
                         h = horizon, xreg = val_df$playoff_games_won)$mean

accuracy_df = data.frame(model = c(rep(&quot;No Xreg&quot;, horizon),
                                   rep(&quot;Games Played&quot;, horizon),
                                   rep(&quot;Games Won&quot;, horizon)),
                         forecasted_views = c(f_no_xreg,
                                              f_playoff_played,
                                              f_playoff_won
                                              ),
                         actual_views = rep(val_df$page_views, 3)
                        )</code></pre>
<p>There are a number of ways to measure error in forecasting. In this case, we‚Äôll use the Mean Average Percent Error (MAPE), which is calculated as follows:</p>
<p><img src="forecasting_with_tom_brady_images/mape_equation.png" width="800px" height="800px" /></p>
<p>e<sub>t</sub> is the difference between the predicted and actual and y<sub>t</sub> is the actual value. As with all error metrics, there are pros and cons to quantifying error with MAPE. The main advantage is ease of interpretation. Telling someone ‚Äúour forecasts were off by 50%‚Äù is easier than saying ‚Äúour forecasts were off by 10,458 units‚Äù. The main disadvantage is that the scale of the error matters. For example, a 10% MAPE on 10 units (1) is a lot smaller than a 10% MAPE on 100,000 units (10K), yet they are treated the same. Additionally, having a small value in the denominator can make a forecast look much worse than it actually is. Thus, if we were forecasting small quantities, a different error metric would be better suited.</p>
<p>With that in mind, let‚Äôs determine how our three approaches performed on the validation set.</p>
<pre class="r"><code>calc_mape = function(predicted_amt, actual_amt){
  return(round(mean(abs(predicted_amt - actual_amt)/actual_amt) * 100, 1))
}

accuracy_df %&gt;% 
  group_by(model) %&gt;% 
  do(mape = calc_mape(.$forecasted_views,
                     .$actual_views
                     )) %&gt;% 
  mutate(mape = unlist(mape),
         model = factor(model)) %&gt;% 
  mutate(model = fct_reorder(model, mape, .desc = FALSE)) %&gt;% 
  ggplot(aes(x = model, y = round(mape, 0),
             fill = model, label = as.character(round(mape, 0)))) + 
  geom_bar(stat = &quot;identity&quot;) + 
  theme_bw() + 
  my_plot_theme() + 
  scale_fill_manual(values = color_values[1:length(unique(accuracy_df$model))]) + 
  xlab(&quot;Forecasting Inputs&quot;) + ylab(&quot;MAPE&quot;) + 
  theme(legend.position = &quot;none&quot;) + 
  geom_label(label.size = 1, size = 10, color = &quot;white&quot;)</code></pre>
<p><img src="/post/forecasting_with_tom_brady_files/figure-html/unnamed-chunk-16-1.png" width="960" /></p>
<p>The model using Games Won as an external regressor performed the best with a less than stellar 114 percent MAPE. We could reformulate our external regressor, try a different forecasting approach, or bring in additional covariates to improve our MAPE, but we‚Äôll keep it simple and just consider only the approaches outlined above.</p>
<p>We figured out which approach works best, and we have all of the data we need to make a traffic forecast. There‚Äôs only one problem: We dont‚Äôt know how many games the Patriots will win during the playoffs. Thus, we‚Äôll need to generate a prediction ‚Äì zero, one, two, or three ‚Äì for the expected number of games won, which in turn will serve as an input into the final model.</p>
</div>
<div id="collecting-betting-lines" class="section level3">
<h3>Collecting Betting Lines</h3>
<p>To help us make an informed decision about the number of games the Patriots will win during the playoffs, we can leverage historical NFL betting lines. If you aren‚Äôt familiar with a betting lines, it‚Äôs a way for odds-makers to encourage an equal number bets for both teams playing in a game.</p>
<p>We‚Äôll again leverage <code>BeautifulSoup</code> and call the <code>collect_betting_line_data.py</code> script from R.</p>
<pre class="python"><code>import urllib2
from bs4 import BeautifulSoup
import re
import pandas as pd
import sys
import os.path
base_url = &quot;https://www.teamrankings.com/nfl/odds-history/results/&quot;
output_location = os.path.join(sys.argv[1], sys.argv[2])
opener = urllib2.build_opener()
opener.addheaders = [(&#39;User-Agent&#39;, &#39;Mozilla/5.0&#39;)]
page = BeautifulSoup(opener.open(base_url), &#39;html.parser&#39;)
table_data = page.find_all(&quot;tr&quot;, {&quot;class&quot;: &quot;text-right nowrap&quot;})
betting_lines = []
for line in table_data:
    line_list = str(line).splitlines()
    try:
        betting_lines.append([re.search(&#39;&lt;td&gt;(.*)&lt;/td&gt;&#39;, line_list[1]).group(1),
                              line_list[4].split(&quot;&gt;&quot;)[1].split(&quot;&lt;&quot;)[0]])
    except:
        betting_lines.append([None, None])

historic_lines_df = pd.DataFrame(betting_lines)
historic_lines_df.columns = [&#39;spread&#39;, &#39;win_pct&#39;]
historic_lines_df.to_csv(output_location, index = False)</code></pre>
<pre class="r"><code>output_file_name = &quot;historic_betting_lines.csv&quot;
py_script_name = &quot;collect_betting_line_data.py&quot;
py_args = c(working_directory, output_file_name)
exe_py_script(py_bin_location, py_script_path, py_script_name, py_args)
betting_lines = read_csv(output_file_name)</code></pre>
Let‚Äôs examine the betting lines data:
<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:600px; overflow-x: scroll; width:720px; ">
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
spread
</th>
<th style="text-align:center;">
win_pct
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
-26.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-24.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-22.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-20.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-19.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-19.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-17.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-17.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-16.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-16.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-15.5
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-15.0
</td>
<td style="text-align:center;">
100.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-14.5
</td>
<td style="text-align:center;">
91.7%
</td>
</tr>
<tr>
<td style="text-align:center;">
-14.0
</td>
<td style="text-align:center;">
90.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
-13.5
</td>
<td style="text-align:center;">
84.3%
</td>
</tr>
<tr>
<td style="text-align:center;">
-13.0
</td>
<td style="text-align:center;">
85.7%
</td>
</tr>
<tr>
<td style="text-align:center;">
-12.5
</td>
<td style="text-align:center;">
76.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-12.0
</td>
<td style="text-align:center;">
81.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
-11.5
</td>
<td style="text-align:center;">
82.8%
</td>
</tr>
<tr>
<td style="text-align:center;">
-11.0
</td>
<td style="text-align:center;">
93.8%
</td>
</tr>
<tr>
<td style="text-align:center;">
-10.5
</td>
<td style="text-align:center;">
82.3%
</td>
</tr>
<tr>
<td style="text-align:center;">
-10.0
</td>
<td style="text-align:center;">
81.1%
</td>
</tr>
<tr>
<td style="text-align:center;">
-9.5
</td>
<td style="text-align:center;">
81.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
-9.0
</td>
<td style="text-align:center;">
73.6%
</td>
</tr>
<tr>
<td style="text-align:center;">
-8.5
</td>
<td style="text-align:center;">
83.3%
</td>
</tr>
<tr>
<td style="text-align:center;">
-8.0
</td>
<td style="text-align:center;">
67.4%
</td>
</tr>
<tr>
<td style="text-align:center;">
-7.5
</td>
<td style="text-align:center;">
76.7%
</td>
</tr>
<tr>
<td style="text-align:center;">
-7.0
</td>
<td style="text-align:center;">
74.1%
</td>
</tr>
<tr>
<td style="text-align:center;">
-6.5
</td>
<td style="text-align:center;">
69.4%
</td>
</tr>
<tr>
<td style="text-align:center;">
-6.0
</td>
<td style="text-align:center;">
69.8%
</td>
</tr>
<tr>
<td style="text-align:center;">
-5.5
</td>
<td style="text-align:center;">
68.3%
</td>
</tr>
<tr>
<td style="text-align:center;">
-5.0
</td>
<td style="text-align:center;">
66.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
-4.5
</td>
<td style="text-align:center;">
68.1%
</td>
</tr>
<tr>
<td style="text-align:center;">
-4.0
</td>
<td style="text-align:center;">
69.0%
</td>
</tr>
<tr>
<td style="text-align:center;">
-3.5
</td>
<td style="text-align:center;">
65.1%
</td>
</tr>
<tr>
<td style="text-align:center;">
-3.0
</td>
<td style="text-align:center;">
55.5%
</td>
</tr>
<tr>
<td style="text-align:center;">
-2.5
</td>
<td style="text-align:center;">
50.4%
</td>
</tr>
<tr>
<td style="text-align:center;">
-2.0
</td>
<td style="text-align:center;">
54.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
-1.5
</td>
<td style="text-align:center;">
54.3%
</td>
</tr>
<tr>
<td style="text-align:center;">
-1.0
</td>
<td style="text-align:center;">
56.2%
</td>
</tr>
<tr>
<td style="text-align:center;">
0.0
</td>
<td style="text-align:center;">
50.0%
</td>
</tr>
</tbody>
</table>
</div>
<p>The interpretation is really simple: A team favored by 12 points (-12) has historically won ~81.2% of their games; bump that spread up to 17 points and there has never been a team favored by 17 points that has lost. Let‚Äôs see what that looks like starting at a zero-point spread, when both teams are perceived by odds-makers to be an equal match.</p>
<pre class="r"><code>betting_lines %&gt;% 
  filter(spread &lt;= 0) %&gt;% 
  mutate(win_pct = substring(as.character(win_pct), 1, 
                                    (nchar(as.character(win_pct)) - 1))) %&gt;% 
  mutate(win_pct = as.numeric(win_pct),
                spread = abs(spread)) %&gt;% 
  rename(favorite = spread) %&gt;% 
  ggplot(aes(x = favorite, y = win_pct)) + 
  geom_point(alpha = 0) + 
  geom_line(alpha = 0) + 
  stat_smooth(span = 2.0, se = FALSE, size = 2, colour = color_values[1]) + 
  ylim(50, 110) + 
  xlim(0, 27) + 
  scale_x_continuous(breaks = seq(0, 25, 5)) + 
  scale_y_continuous(breaks = seq(50, 110, 5)) + 
  theme_bw() + 
  my_plot_theme() + 
  xlab(&quot;Point Favorite&quot;) + ylab(&quot;Chance of Winning&quot;) + 
  geom_vline(xintercept = 7, size = 2, colour = color_values[2]) + 
  geom_vline(xintercept = 5, size = 2, colour = color_values[3]) + 
  geom_vline(xintercept = 3, size = 2, colour = color_values[4]) + 
  annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 88, ymax = 90, fill = color_values[2]) + 
  annotate(&quot;text&quot;, label = &quot;Game 1 Spread&quot;, x = 23, y = 89, size = 8, color = color_values[2]) + 
  annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 85, ymax = 87, fill = color_values[3]) + 
  annotate(&quot;text&quot;, label = &quot;Game 2 Spread&quot;, x = 23, y = 86, size = 8, color = color_values[3]) + 
  annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 82, ymax = 84, fill = color_values[4]) + 
  annotate(&quot;text&quot;, label = &quot;Game 3 Spread&quot;, x = 23, y = 83, size = 8, color = color_values[4])</code></pre>
<p><img src="/post/forecasting_with_tom_brady_files/figure-html/unnamed-chunk-21-1.png" width="960" /></p>
<p>We only know the spread for Game 1 because we are generating our forecasts at the beginning of January. The Patriots are favored by seven points, and historically teams favored by this amount win ~73% of games. So I‚Äôm feeling at least one win. What about two? Here we are going to make an educated guess. We can assume that each subsequent game will be more challenging for the Patriots, so we‚Äôll make a prediction of a five point favorite. Finally, if the Patriots play in the Superbowl, let‚Äôs predict they‚Äôll be a three point favorite. If we assume that the outcome of each playoff game is independent of the prior game (which, barring a major injury to a key player, is a reasonable assumption), we can calculate the probability of each of these scenarios unfolding:</p>
<p><img src="forecasting_with_tom_brady_images/win_prob.png" width="800px" height="800px" /> There is about a 50% chance the Patriots will win two playoff games, so let‚Äôs pick two as our number. Before proceeding to the end result, I‚Äôll briefly discuss how the forecasts are being generated.</p>
</div>
<div id="seasonal-arimax-model" class="section level3">
<h3>Seasonal ARIMAX Model</h3>
<p>Let‚Äôs train our final model and examine the coefficients.</p>
<pre class="r"><code>input_ts = ts(page_views %&gt;% 
              filter(part == &#39;train&#39;) %&gt;% 
              pull(page_views),
              frequency = 12
              )
xreg_train = page_views %&gt;% 
             filter(part == &#39;train&#39;) %&gt;% 
             pull(playoff_games_won)
model_fit = auto.arima(input_ts, xreg = xreg_train)
print(summary(model_fit))</code></pre>
<pre class="r"><code>## Series: input_ts 
## Regression with ARIMA(1,1,1)(0,1,1)[12] errors 
## 
## Coefficients:
##          ar1      ma1     sma1  xreg_train
##       0.2673  -0.8559  -0.7373   296550.82
## s.e.  0.1458   0.0723   0.2563    36020.02
## 
## sigma^2 estimated as 1.28e+10:  log likelihood=-930.05
## AIC=1870.1   AICc=1871.02   BIC=1881.41
## 
## Training set error measures:
##                     ME     RMSE      MAE       MPE     MAPE      MASE        ACF1
## Training set -22993.67 101058.3 61230.45 -26.36236 38.57438 0.6260494 -0.01938565</code></pre>
<p>The great thing about the <code>auto.arima</code> function is that it does the hard work of identifying the best model specification from our training data. While this is a huge time-saver, it helps to understand how and why certain parameters were selected. If you happen to be a forecasting expert and just want to know how to implement the model, feel free to skip this next section.</p>
<p>Our model is <code>ARIMA(1,1,1)(0,1,1)[12]</code>. Let‚Äôs first focus on the first part <code>ARIMA(1,1,1)</code>.</p>
<p>ARIMA stands for Auto-Regressive Integrated Moving Average, which is why it is abbreviated. Identifying the Integrated part ARIMA(1, 1, 1) is the first thing we do. It says ‚Äòthis is how much you need to difference (Y~t - Y<sub>t-1</sub>) our time series by to make it stationary on the mean. Cool story Hansel. Now in English. Stationary implies that the average (or variance, or any other parameter) of our time series remains constant across time. If we have an upward or downward trend, our mean is not stationary (its changing!), so the model captures how much it is going up or down by each time step, and then subtracts that from each value so it remains flat (or stationary). Indeed, if a time series is stationary, it means that it‚Äôs values do not depend on where we are in the time series.</p>
<p>Next the <strong>Auto-Regressive</strong> or <strong>(AR(1))</strong> part. Auto-regressive roughly translates to ‚Äòregressed on itself‚Äô, and implies that we can learn something about Y<sub>t+1</sub> from Y<sub>t</sub>. Said differently, prior values (in this case from 1 prior time-step) are good indicators of subsequent future values, so we capture this with an auto-regressive term.</p>
<p>Finally the <strong>Moving Average</strong> or <strong>(MA(1))</strong> part. Moving-average is like the AR part, in that we use prior values to inform our prediction of future values, but instead of focusing on the actual values we focus instead on prior errors, specifically our forecasting errors. These errors are computed as we fit the model, and like many things in life, we use our past errors to inform our future predictions.</p>
<p>Now let‚Äôs discuss the second part: <code>(0,1,1)[12]</code>. This is the seasonality portion of our model and can be interpreted similarly to the first part. The model is determining the difference in each month‚Äôs number of views across time, so Jan. 2015 - Jan. 2014 - Jan 2013‚Ä¶you get the point. That‚Äôs the integrated part. The model also calculates a historical moving average with exponential weighting. The amount of weighting (or smoothing) is determined by the <code>sma1</code> coefficient contained in the above model. Coefficients that are closer to 1 indicate that more months (across history) are being used to determine how much future months will differ from the average of previous months.</p>
<p>Finally the coefficient for our external regressor ‚Äì number of post-season games won ‚Äì has a value of 296550. This coefficient is interpreted just like a linear regression model; for each additional Patriot‚Äôs post-season win, we expect ~296K more visits to the website.</p>
<p>If that all makes sense, let‚Äôs test our model on the final data, with our external variable set to two playoff games, and see how our prediction of Tom Brady‚Äôs page views compared to what actually happened. In essence, we are saying ‚ÄúThe Patriots will make the superbowl but wont win.‚Äù It turns out betting against the Patriots in the superbowl can be a bad move, something I‚Äôve experienced firsthand üòï.</p>
<pre class="r"><code>actual_views = page_views %&gt;% 
  filter(part == &#39;test&#39;) %&gt;% 
  pull(page_views)
# prediction for how many playoff games we think the Patriots will win
games_won = 2
test_xreg = c(games_won, games_won)
forecasted_views = forecast(model_fit,
                              h = horizon,
                              xreg = test_xreg)$mean
print(paste0(&quot;MAPE IS: &quot; , calc_mape(forecasted_views, actual_views), &quot;%&quot;))</code></pre>
<pre class="r"><code>## MAPE IS: 34.9%</code></pre>
<p>Our MAPE is ~35%, which is considerably better than the MAPE on our holdout set. However, our prediction of the Patriots only winning two games was wrong. The patriots won three post season games and beat the Seattle Seahawks 28-24 to win the superbowl. So what would‚Äôve happened if the value of our external regressor was correct (i.e., three instead of two)?</p>
<pre class="r"><code>games_won = 3
test_xreg = c(games_won, games_won)
forecasted_views = forecast(model_fit,
                              h = horizon,
                              xreg = test_xreg)$mean
print(paste0(&quot;MAPE IS: &quot; , calc_mape(forecasted_views, actual_views), &quot;%&quot;))</code></pre>
<pre class="r"><code>## MAPE IS: 70.7%</code></pre>
<p>Hang on a second üí¶. The model with the correct number of playoff games won (three) had lower accuracy? Yes, and here‚Äôs why: Across the history of our time series, the Patriots never won three playoff games. They had only won zero, one or two games. Therefore, we are extrapolating to values not contained in our data set, which can be a recipe for disaster. If you look at the change in our forecast as we increase the number of playoff games won by one, we expect an additional 296K visitors. We are making the assumption that there is a linear relationship between wins and page views, such that each additional win generates +296K views. This is not the case, and the incorrect assumption is reflected in the accuracy of the resulting forecast.</p>
<p>Hopefully this post has eliminated some of the mystery around creating forecasts with external regressors. This is common topic of confusion when just starting to implement forecasts in R. However, it is no different than building a regular regression model. Happy forecasting!</p>
</div>

      </div>

      


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/forecasting">Forecasting</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/r">R</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/python">Python</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/web-scraping">Web Scraping</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/arima">ARIMA</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/sports-betting">Sports Betting</a>
  
</div>



    </div>
  </div>

</article>



<div class="article-container article-widget">
  <div class="hr-light"></div>
  <h3>Related</h3>
  <ul>
    
    <li><a href="/post/counterfactual_prediction.html">Establishing Causality with Counterfactual Prediction</a></li>
    
    <li><a href="/post/time_series_outlier_detection.html">Time Series Outlier Detection</a></li>
    
    <li><a href="/post/error_handling_markdown.html">Exception Handling with Ron Burgundy</a></li>
    
    <li><a href="/post/early_trend_detection.html">Early Trend Detection</a></li>
    
    <li><a href="/post/feature_selection_wine.html">Feature Selection for the Wine Connoisseur</a></li>
    
  </ul>
</div>




<div class="article-container">
  
<section id="comments">
  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "thecodeforest" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Mark LeBoeuf &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script id="dsq-count-scr" src="//thecodeforest.disqus.com/count.js" async></script>
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

